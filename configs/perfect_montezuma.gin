# Parameters for DeterministicMCTSAgent:
# ==============================================================================
DeterministicMCTSAgent.avoid_loops = True
DeterministicMCTSAgent.gamma = 0.99
DeterministicMCTSAgent.n_passes = 10
DeterministicMCTSAgent.value_traits_class = @alpacka.agents.deterministic_mcts.ScalarValueTraits
DeterministicMCTSAgent.value_accumulator_class = @alpacka.agents.deterministic_mcts.EnsembleValueAccumulator
DeterministicMCTSAgent.ensemble_size = 20
DeterministicMCTSAgent.ensemble_mask_size = 10
DeterministicMCTSAgent.render_rollout = True

# Parameters for EnsembleValueAccumulator:
# ==============================================================================
EnsembleValueAccumulator.kappa = 3

# Parameters for EnsembleNetwork:
# ==============================================================================
EnsembleNetwork.network_fn = @KerasNetwork
EnsembleNetwork.n_networks = 20

# Parameters for RMSprop:
# ==============================================================================
RMSprop.lr = 2.5e-4

# Parameters for KerasNetwork:
# ==============================================================================
KerasNetwork.loss = 'mean_squared_error'
KerasNetwork.loss_weights = None
KerasNetwork.metrics = ['mae', 'mse']
KerasNetwork.model_fn = @alpacka.networks.keras.mlp
KerasNetwork.optimizer = @tf.keras.optimizers.RMSprop()
KerasNetwork.train_callbacks = None
KerasNetwork.weight_decay = 0.

# Parameters for LocalBatchStepper:
# ==============================================================================
# None.

# Parameters for mlp:
# ==============================================================================
mlp.hidden_sizes = (50, 50)
mlp.activation = 'relu'
mlp.output_activation = None

# Parameters for Runner:
# ==============================================================================
Runner.agent_class = @alpacka.agents.DeterministicMCTSAgent
Runner.batch_stepper_class = @alpacka.batch_steppers.RayBatchStepper
Runner.env_class = @alpacka.envs.ToyMR
Runner.episode_time_limit = 300
Runner.n_envs = 8
Runner.n_epochs = 1000
Runner.n_precollect_epochs = 2
Runner.network_class = @alpacka.networks.EnsembleNetwork
Runner.trainer_class = @alpacka.trainers.SupervisedTrainer
Runner.log_rollout_every_n_epochs = 25

# Parameters for ScalarValueAccumulator:
# ==============================================================================
# None.

# Parameters for ScalarValueTraits:
# ==============================================================================
ScalarValueTraits.dead_end_value = -0.2
ScalarValueTraits.avoid_history_coeff = -0.2

# Parameters for SupervisedTrainer:
# ==============================================================================
SupervisedTrainer.batch_size = 32
SupervisedTrainer.n_steps_per_epoch = 64
SupervisedTrainer.replay_buffer_capacity = 1000
SupervisedTrainer.replay_buffer_sampling_hierarchy = ['solved']
SupervisedTrainer.target = @alpacka.trainers.supervised.target_value

# Parameters for target_value:
# ==============================================================================
# None.

# Parameters for ToyMR:
# ==============================================================================
ToyMR.map_file = %ToyMRMaps.ONE_ROOM
ToyMR.max_lives = 1
ToyMR.absolute_coordinates = False
ToyMR.trap_reward = 0
ToyMR.doors_keys_scale = 1
ToyMR.save_enter_cell = False


# Parameters for RMSprop:
# ==============================================================================
RMSprop.learning_rate = 0.00025
